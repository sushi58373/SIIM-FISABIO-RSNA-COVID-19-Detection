{"cells":[{"cell_type":"markdown","metadata":{},"source":["# [TRAIN] Siim EFNB7 tf.keras (study) \n","[[Notebook] using TPU](https://www.kaggle.com/xhlulu/ranzcr-efficientnet-tpu-training)  \n","[[Notebook] Reference Notebook](https://www.kaggle.com/h053473666/siim-covid19-efnb7-train-study)  \n","\n","* Cutmix  \n","    [[Notebook] CutMix and MixUp on GPU/TPU](https://www.kaggle.com/cdeotte/cutmix-and-mixup-on-gpu-tpu)\n"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2021-08-01T02:13:33.687046Z","iopub.status.busy":"2021-08-01T02:13:33.686309Z","iopub.status.idle":"2021-08-01T02:13:42.605766Z","shell.execute_reply":"2021-08-01T02:13:42.604800Z","shell.execute_reply.started":"2021-08-01T02:13:33.686925Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting efficientnet\n","  Downloading efficientnet-1.1.1-py3-none-any.whl (18 kB)\n","Collecting keras-applications<=1.0.8,>=1.0.7\n","  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n","\u001b[K     |████████████████████████████████| 50 kB 661 kB/s eta 0:00:01\n","\u001b[?25hRequirement already satisfied: scikit-image in /opt/conda/lib/python3.7/site-packages (from efficientnet) (0.18.1)\n","Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.19.5)\n","Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (2.10.0)\n","Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.15.0)\n","Requirement already satisfied: imageio>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet) (2.9.0)\n","Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet) (7.2.0)\n","Requirement already satisfied: scipy>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet) (1.5.4)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet) (1.1.1)\n","Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet) (3.4.1)\n","Requirement already satisfied: networkx>=2.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet) (2.5)\n","Requirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet) (2021.4.8)\n","Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2.4.7)\n","Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2.8.1)\n","Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (1.3.1)\n","Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx>=2.0->scikit-image->efficientnet) (4.4.2)\n","Installing collected packages: keras-applications, efficientnet\n","Successfully installed efficientnet-1.1.1 keras-applications-1.0.8\n"]}],"source":["!pip install efficientnet"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2021-08-01T02:13:42.608475Z","iopub.status.busy":"2021-08-01T02:13:42.607982Z","iopub.status.idle":"2021-08-01T02:13:50.558312Z","shell.execute_reply":"2021-08-01T02:13:50.557359Z","shell.execute_reply.started":"2021-08-01T02:13:42.608414Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["numpy version: 1.19.5\n","TF version: 2.4.1\n","Hub version: 0.12.0\n","Physical devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"]}],"source":["import os\n","import efficientnet.tfkeras as efn\n","import numpy as np\n","import pandas as pd\n","from kaggle_datasets import KaggleDatasets # what?\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf\n","import tensorflow.keras.backend as K\n","from sklearn.model_selection import GroupKFold\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import GroupKFold\n","from sklearn.metrics import roc_auc_score, precision_recall_curve\n","import shutil\n","\n","import tensorflow_hub as tfhub\n","import tensorflow.keras.backend as K\n","\n","import random\n","import albumentations\n","from PIL import Image, ImageOps, ImageEnhance\n","from albumentations.core.transforms_interface import ImageOnlyTransform\n","from albumentations.augmentations import functional as F\n","\n","import glob\n","\n","print('numpy version:',np.__version__)\n","print('TF version:', tf.__version__)\n","print('Hub version:', tfhub.__version__)\n","print('Physical devices:', tf.config.list_physical_devices())"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2021-08-01T02:13:50.560232Z","iopub.status.busy":"2021-08-01T02:13:50.559948Z","iopub.status.idle":"2021-08-01T02:13:50.566475Z","shell.execute_reply":"2021-08-01T02:13:50.565640Z","shell.execute_reply.started":"2021-08-01T02:13:50.560205Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Use model Version : V2\n"]}],"source":["# Config\n","\n","v1 = False\n","v2 = True\n","\n","def seed_everything(SEED):\n","    os.environ['PYTHONHASHSEED'] = str(SEED)\n","    random.seed(SEED)\n","    np.random.seed(SEED)\n","    tf.random.set_seed(SEED)\n","    os.environ['TF_CUDNN_DETERMINISTIC'] = str(SEED)\n","\n","print(f\"Use model Version : {'V1' if v1 else 'V2'}\")\n","seed_everything(42)"]},{"cell_type":"markdown","metadata":{},"source":["# CutMix"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2021-08-01T02:13:50.568509Z","iopub.status.busy":"2021-08-01T02:13:50.568158Z","iopub.status.idle":"2021-08-01T02:13:50.589714Z","shell.execute_reply":"2021-08-01T02:13:50.588685Z","shell.execute_reply.started":"2021-08-01T02:13:50.568479Z"},"trusted":true},"outputs":[],"source":["# Define CUTMIX\n","\n","def onehot(image, label):\n","    CLASSES = 4 # study_level class\n","    return image, tf.one_hot(label, CLASSES)\n","\n","def cutmix(image, label, PROBABILITY = 1.0):\n","    # input_image : is a batch of images of size [n, dim, dim, 3] not a single image of [dim, dim, 3]\n","    # output : a batch of images with cutmix applied\n","    DIM = 768\n","    CLASSES = 4\n","    AUG_BATCH = 128\n","\n","    imgs = []\n","    labs = []\n","    for j in range(AUG_BATCH):\n","        # DO CUTMIX WITH PROBABILITY DEFINED ABOVE\n","        P = tf.cast(tf.random.uniform([],0,1) <= PROBABILITY, tf.int32)\n","        # CHOOSE RANDOM IMAGE TO CUTMIX WITH\n","        # tf.cast(data, type) -> type 에 맞춰서 data 의 형태를 바꿔준다.\n","        k = tf.cast(tf.random.uniform([],0,AUG_BATCH), tf.int32)\n","        # CHOOSE RANDOM LOCATION\n","        x = tf.cast(tf.random.uniform([],0,DIM), tf.int32)\n","        y = tf.cast(tf.random.uniform([],0,DIM), tf.int32)\n","        b = tf.random.uniform([],0,1) # this is beta dist with alpha=1.0\n","        WIDTH = tf.cast(DIM * tf.math.sqrt(1-b), tf.int32) * P\n","        ya = tf.math.maximum(0, y-WIDTH//2)\n","        yb = tf.math.minimum(DIM, y+WIDTH//2)\n","        xa = tf.math.maximum(0, x-WIDTH//2)\n","        xb = tf.math.minimum(DIM, x+WIDTH//2)\n","\n","        # MAKE CUTMIX IMAGE\n","        one = image[j, ya:yb, 0:xa, :]\n","        two = image[k, ya:yb, xa:xb, :]\n","        three = image[j, ya:yb, xb:DIM, :]\n","        middle = tf.concat([one, two, three], axis=1)\n","        img = tf.concat([image[j, 0:ya, :, :], middle, image[j,yb:DIM,:,:]], axis=0)\n","        imgs.append(img)\n","\n","        # MAKE CUTMIX LABEL\n","        a = tf.cast(WIDTH * WIDTH/DIM/DIM, tf.float32)\n","        if len(label.shape) == 1:\n","            lab1 = tf.one_hot(label[j], CLASSES)\n","            lab2 = tf.one_hot(label[k], CLASSES)\n","        else:\n","            lab1 = tf.cast(label[j,], tf.float32)\n","            lab2 = tf.cast(label[k,], tf.float32)\n","        labs.append((1-a)*lab1 + a*lab2)\n","\n","    # RESHAPE HACK SO TPU COMPILER KNOWS SHAPE OF OUTPUT TENSOR \n","    # (maybe use Python typing instead?)\n","    image2 = tf.reshape(tf.stack(imgs), (AUG_BATCH,DIM,DIM,3))\n","    label2 = tf.reshape(tf.stack(labs), (AUG_BATCH,CLASSES))\n","    return image2, label2\n","\n","def transform_cutmix(image, label):\n","    # THIS FUNCTION APPLIES BOTH CUTMIX AND MIXUP\n","    DIM = 768\n","    CLASSES = 4\n","    SWITCH = 0.5\n","    CUTMIX_PROB = 0.666\n","    AUG_BATCH = 128\n","    # FOR SWITCH PERCENT OF TIME WE DO CUTMIX AND (1-SWITCH) WE DO MIXUP\n","    image2, label2 = cutmix(image, label, CUTMIX_PROB)\n","    imgs = []\n","    labs = []\n","    for j in range(AUG_BATCH):\n","        #P = tf.cast( tf.random.uniform([],0,1)<=SWITCH, tf.float32)\n","        imgs.append(image2[j,])\n","        labs.append(label2[j,])\n","    # RESHAPE HACK SO TPU COMPILER KNOWS SHAPE OF OUTPUT TENSOR\n","    image4 = tf.reshape(tf.stack(imgs), (AUG_BATCH, DIM, DIM, 3))\n","    label4 = tf.reshape(tf.stack(labs), (AUG_BATCH, CLASSES))\n","    return image4, label4"]},{"cell_type":"markdown","metadata":{},"source":["## Display CutMix Augmentation"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2021-08-01T02:13:50.591660Z","iopub.status.busy":"2021-08-01T02:13:50.591074Z","iopub.status.idle":"2021-08-01T02:13:50.605087Z","shell.execute_reply":"2021-08-01T02:13:50.603886Z","shell.execute_reply.started":"2021-08-01T02:13:50.591619Z"},"trusted":true},"outputs":[],"source":["# DISPLAY CUTMIX AUGMENTATION\n","display_image = False\n","if display_image:\n","    i = 0\n","    detail_path = '/new_resized_data/image_512/'\n","    valid_paths = GCS_DS_PATH + detail_path + df[df['fold'] == i]['id'] + '.png'\n","    train_paths = GCS_DS_PATH + detail_path + df[df['fold'] != i]['id'] + '.png'\n","    valid_labels = df[df['fold'] == i][label_cols].values\n","    train_labels = df[df['fold'] != i][label_cols].values\n","    img_size = 512\n","    BATCH_SIZE = 128\n","    # train image\n","    decoder = build_decoder(with_labels=True,\n","                            target_size=(img_size, img_size),\n","                            ext='png')\n","    # valid image\n","    test_decoder = build_decoder(with_labels=False, \n","                                 target_size=(img_size, img_size),\n","                                 ext='png')\n","\n","    train_dataset = build_dataset(train_paths,\n","                                  train_labels,\n","                                  bsize=BATCH_SIZE,\n","                                  decode_fn=decoder)\n","\n","    valid_dataset = build_dataset(valid_paths,\n","                                  valid_labels,\n","                                  bsize=BATCH_SIZE,\n","                                  decode_fn=decoder,\n","                                  repeat=False,\n","                                  shuffle=False,\n","                                  augment=False,\n","                                  do_mix=False)\n","    # iterator 가 아니다. repeat() 로 batch 를 읽는다.\n","    sample = train_dataset.repeat()\n","    for (img, label) in sample:\n","        img = img[:16]\n","        label = label[:16]\n","        break"]},{"cell_type":"markdown","metadata":{},"source":["# AugMix Augmentation\n","[[github] Original AugMix github](https://github.com/google-research/augmix/blob/master/augment_and_mix.py)  \n","[[Notebook] Augmix for TPU](https://www.kaggle.com/szacho/augmix-data-augmentation-on-tpu)"]},{"cell_type":"markdown","metadata":{},"source":["### Transformations\n","These are simple augmentations used by AugMix. Every function takes `image` and `level` (integer from 1 to 10) as arguments. The second one indicates how much variation will particular transformation yield, in other words, how strong it will be.\n","\n","Translate, shear and rotate augmentations are based on [this notebook](https://www.kaggle.com/cdeotte/rotation-augmentation-gpu-tpu-0-96).  \n","\n","(구현 아직 안됨)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2021-08-01T02:13:50.607335Z","iopub.status.busy":"2021-08-01T02:13:50.606936Z","iopub.status.idle":"2021-08-01T02:13:50.633252Z","shell.execute_reply":"2021-08-01T02:13:50.632260Z","shell.execute_reply.started":"2021-08-01T02:13:50.607295Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","from PIL import Image, ImageOps, ImageEnhance\n","\n","# ImageNet code should change this value\n","IMAGE_SIZE = 768\n","\n","\n","def int_parameter(level, maxval):\n","    \"\"\"Helper function to scale `val` between 0 and maxval .\n","    Args:\n","    level: Level of the operation that will be between [0, `PARAMETER_MAX`].\n","    maxval: Maximum value that the operation can have. This will be scaled to\n","      level/PARAMETER_MAX.\n","    Returns:\n","    An int that results from scaling `maxval` according to `level`.\n","    \"\"\"\n","    return int(level * maxval / 10)\n","\n","\n","def float_parameter(level, maxval):\n","    \"\"\"Helper function to scale `val` between 0 and maxval.\n","    Args:\n","    level: Level of the operation that will be between [0, `PARAMETER_MAX`].\n","    maxval: Maximum value that the operation can have. This will be scaled to\n","      level/PARAMETER_MAX.\n","    Returns:\n","    A float that results from scaling `maxval` according to `level`.\n","    \"\"\"\n","    return float(level) * maxval / 10.\n","\n","\n","def sample_level(n):\n","    return np.random.uniform(low=0.1, high=n)\n","\n","\n","def autocontrast(pil_img, _):\n","    return ImageOps.autocontrast(pil_img)\n","\n","\n","def equalize(pil_img, _):\n","    return ImageOps.equalize(pil_img)\n","\n","\n","def posterize(pil_img, level):\n","    level = int_parameter(sample_level(level), 4)\n","    return ImageOps.posterize(pil_img, 4 - level)\n","\n","\n","def rotate(pil_img, level):\n","    degrees = int_parameter(sample_level(level), 30)\n","    if np.random.uniform() > 0.5:\n","        degrees = -degrees\n","    return pil_img.rotate(degrees, resample=Image.BILINEAR)\n","\n","\n","def solarize(pil_img, level):\n","    level = int_parameter(sample_level(level), 256)\n","    return ImageOps.solarize(pil_img, 256 - level)\n","\n","\n","def shear_x(pil_img, level):\n","    level = float_parameter(sample_level(level), 0.3)\n","    if np.random.uniform() > 0.5:\n","        level = -level\n","    return pil_img.transform((IMAGE_SIZE, IMAGE_SIZE),\n","                           Image.AFFINE, (1, level, 0, 0, 1, 0),\n","                           resample=Image.BILINEAR)\n","\n","\n","def shear_y(pil_img, level):\n","    level = float_parameter(sample_level(level), 0.3)\n","    if np.random.uniform() > 0.5:\n","        level = -level\n","    return pil_img.transform((IMAGE_SIZE, IMAGE_SIZE),\n","                           Image.AFFINE, (1, 0, 0, level, 1, 0),\n","                           resample=Image.BILINEAR)\n","\n","\n","def translate_x(pil_img, level):\n","    level = int_parameter(sample_level(level), IMAGE_SIZE / 3)\n","    if np.random.random() > 0.5:\n","        level = -level\n","    return pil_img.transform((IMAGE_SIZE, IMAGE_SIZE),\n","                           Image.AFFINE, (1, 0, level, 0, 1, 0),\n","                           resample=Image.BILINEAR)\n","\n","\n","def translate_y(pil_img, level):\n","    level = int_parameter(sample_level(level), IMAGE_SIZE / 3)\n","    if np.random.random() > 0.5:\n","        level = -level\n","    return pil_img.transform((IMAGE_SIZE, IMAGE_SIZE),\n","                           Image.AFFINE, (1, 0, 0, 0, 1, level),\n","                           resample=Image.BILINEAR)\n","\n","\n","# operation that overlaps with ImageNet-C's test set\n","def color(pil_img, level):\n","    level = float_parameter(sample_level(level), 1.8) + 0.1\n","    return ImageEnhance.Color(pil_img).enhance(level)\n","\n","\n","# operation that overlaps with ImageNet-C's test set\n","def contrast(pil_img, level):\n","    level = float_parameter(sample_level(level), 1.8) + 0.1\n","    return ImageEnhance.Contrast(pil_img).enhance(level)\n","\n","\n","# operation that overlaps with ImageNet-C's test set\n","def brightness(pil_img, level):\n","    level = float_parameter(sample_level(level), 1.8) + 0.1\n","    return ImageEnhance.Brightness(pil_img).enhance(level)\n","\n","\n","# operation that overlaps with ImageNet-C's test set\n","def sharpness(pil_img, level):\n","    level = float_parameter(sample_level(level), 1.8) + 0.1\n","    return ImageEnhance.Sharpness(pil_img).enhance(level)\n","\n","\n","augmentations = [\n","    autocontrast, equalize, posterize, rotate, solarize, shear_x, shear_y,\n","    translate_x, translate_y\n","]\n","\n","augmentations_all = [\n","    autocontrast, equalize, posterize, rotate, solarize, shear_x, shear_y,\n","    translate_x, translate_y, color, contrast, brightness, sharpness\n","]"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2021-08-01T02:13:50.635281Z","iopub.status.busy":"2021-08-01T02:13:50.634871Z","iopub.status.idle":"2021-08-01T02:13:50.650975Z","shell.execute_reply":"2021-08-01T02:13:50.648763Z","shell.execute_reply.started":"2021-08-01T02:13:50.635238Z"},"trusted":true},"outputs":[],"source":["# Augmix\n","import numpy as np\n","from PIL import Image\n","\n","# CIFAR-10 constants\n","MEAN = [0.4914, 0.4822, 0.4465]\n","STD = [0.2023, 0.1994, 0.2010]\n","\n","def numpy_to_tensor(arg):\n","    arg = tf.convert_to_tensor(arg, dtype=tf.float32)\n","    return arg\n","\n","def normalize(image):\n","    \"\"\"Normalize input image channel-wise to zero mean and unit variance.\"\"\"\n","    image = image.transpose(2, 0, 1)  # Switch to channel-first\n","    mean, std = np.array(MEAN), np.array(STD)\n","    image = (image - mean[:, None, None]) / std[:, None, None]\n","    return image.transpose(1, 2, 0)\n","\n","\n","def apply_op(image, op, severity):\n","    image = K.clip(image * 255., 0, 255)\n","    image = K.cast(image, dtype=tf.uint8)\n","\n","    pil_img = Image.fromarray(image)  # Convert to PIL.Image\n","    pil_img = op(pil_img, severity)\n","    return np.asarray(pil_img) / 255.\n","\n","\n","def augment_and_mix(image, severity=3, width=3, depth=-1, alpha=1.):\n","    \"\"\"Perform AugMix augmentations and compute mixture.\n","    Args:\n","    image: Raw input image as float32 np.ndarray of shape (h, w, c)\n","    severity: Severity of underlying augmentation operators (between 1 to 10).\n","    width: Width of augmentation chain\n","    depth: Depth of augmentation chain. -1 enables stochastic depth uniformly\n","      from [1, 3]\n","    alpha: Probability coefficient for Beta and Dirichlet distributions.\n","    Returns:\n","    mixed: Augmented and mixed image.\n","    \"\"\"\n","    ws = np.float32(np.random.dirichlet([alpha] * width))\n","    m = np.float32(np.random.beta(alpha, alpha))\n","    \n","    image = tf.convert_to_tensor(image)\n","    mix = np.zeros_like(image)\n","\n","    for i in range(width):\n","#        image_aug = image.copy()\n","        image_aug = tf.identity(image)\n","        d = depth if depth > 0 else np.random.randint(1, 4)\n","        for _ in range(d):\n","            op = np.random.choice(augmentations)\n","            image_aug = apply_op(image_aug, op, severity)\n","        # Preprocessing commutes since all coefficients are convex\n","        mix += ws[i] * normalize(image_aug)\n","\n","    mixed = (1 - m) * normalize(image) + m * mix\n","    return numpy_to_tensor(mixed)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2021-08-01T02:13:50.655150Z","iopub.status.busy":"2021-08-01T02:13:50.654619Z","iopub.status.idle":"2021-08-01T02:13:50.678866Z","shell.execute_reply":"2021-08-01T02:13:50.677554Z","shell.execute_reply.started":"2021-08-01T02:13:50.655119Z"},"trusted":true},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(3,), dtype=int32, numpy=array([2, 3, 4], dtype=int32)>"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["a = tf.constant([2,3,4])\n","a"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2021-08-01T02:13:50.681137Z","iopub.status.busy":"2021-08-01T02:13:50.680673Z","iopub.status.idle":"2021-08-01T02:13:50.685852Z","shell.execute_reply":"2021-08-01T02:13:50.685147Z","shell.execute_reply.started":"2021-08-01T02:13:50.681095Z"},"trusted":true},"outputs":[{"data":{"text/plain":["array([2, 3, 4], dtype=int32)"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["a.numpy()"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2021-08-01T02:13:50.687757Z","iopub.status.busy":"2021-08-01T02:13:50.687266Z","iopub.status.idle":"2021-08-01T02:13:50.701387Z","shell.execute_reply":"2021-08-01T02:13:50.700641Z","shell.execute_reply.started":"2021-08-01T02:13:50.687691Z"},"trusted":true},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(3,), dtype=int32, numpy=array([2, 3, 5], dtype=int32)>"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["tf.constant([2,3,5])"]},{"cell_type":"markdown","metadata":{},"source":["# Function for Datasets & TPU"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2021-08-01T02:13:50.703564Z","iopub.status.busy":"2021-08-01T02:13:50.702884Z","iopub.status.idle":"2021-08-01T02:13:50.726947Z","shell.execute_reply":"2021-08-01T02:13:50.725850Z","shell.execute_reply.started":"2021-08-01T02:13:50.703519Z"},"trusted":true},"outputs":[],"source":["def auto_select_accelerator():\n","    try:\n","        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n","        tf.config.experimental_connect_to_cluster(tpu)\n","        tf.tpu.experimental.initialize_tpu_system(tpu)\n","        strategy = tf.distribute.experimental.TPUStrategy(tpu)\n","        print(\"Running on TPU:\", tpu.master())\n","    except ValueError:\n","        strategy = tf.distribute.get_strategy()\n","    print(f\"Running on {strategy.num_replicas_in_sync} replicas\")\n","    \n","    return strategy\n","\n","# decoding\n","def build_decoder(with_labels=True, target_size=(256, 256), ext='jpg'):\n","    def decode(path):\n","        file_bytes = tf.io.read_file(path)\n","\n","        if ext == 'png':\n","            img = tf.image.decode_png(file_bytes, channels=3)\n","        elif ext in ['jpg', 'jpeg']:\n","            img = tf.image.decode_jpeg(file_bytes, channels=3)\n","        else:\n","            raise ValueError(\"Image extension not supported\")\n","        img = tf.cast(img, tf.float32) / 255.0\n","        img = tf.image.resize(img, target_size)\n","\n","        return img\n","\n","    def decode_with_labels(path, label):\n","        return decode(path), label\n","    \n","    return decode_with_labels if with_labels else decode\n","\n","# augmentation function\n","def build_augmenter(with_labels=True):\n","    def augment(img):\n","        img = tf.image.random_flip_left_right(img)\n","#        img = tf.image.random_flip_up_down(img)\n","        img = tf.image.random_saturation(img, SATURATION[0], SATURATION[1])\n","        img = tf.image.random_contrast(img, CONTRAST[0], CONTRAST[1])\n","        img = tf.image.random_brightness(img, BRIGHTNESS)\n","        \n","        return img\n","    # augmenation experiment -> best way : H Flip, rotate, zoom, brightness, cutout\n","    \n","    def augment_with_labels(img, label):\n","        return augment(img), label\n","    \n","    return augment_with_labels if with_labels else augment\n","\n","# augmix\n","def build_augmixer(with_labels=True):\n","    def augmixer(img):\n","        img = augment_and_mix(img, severity=3, width=3, depth=-1, alpha=1.)\n","        return img\n","    \n","    def augmix_with_labels(img, label):\n","        return augmixer(img), label\n","    \n","    return augmix_with_labels if with_labels else augmixer\n","\n","\n","# dataset\n","def build_dataset(paths, \n","                  labels=None, bsize=128, cache=True,\n","                  decode_fn=None, \n","                  augment_fn=None,\n","                  augmix_fn=None,\n","                  repeat=True, \n","                  shuffle=1024,\n","                  augment=False, \n","                  do_cutmix = False,\n","                  do_augmix = False,\n","                  cache_dir=\"\"):\n","    \n","    if cache_dir != \"\" and cache is True:\n","        os.makedirs(cache_dir, exist_ok=True)\n","    \n","    if decode_fn is None:\n","        decode_fn = build_decoder(labels is not None)\n","    \n","    if augment_fn is None:\n","        augment_fn = build_augmenter(labels is not None)\n","        \n","    if augmix_fn is None:\n","        augmix_fn = build_augmixer(labels is not None)\n","    \n","    \n","    AUTO = tf.data.experimental.AUTOTUNE\n","    slices = paths if labels is None else (paths, labels)\n","    \n","    dset = tf.data.Dataset.from_tensor_slices(slices)\n","    dset = dset.map(decode_fn, num_parallel_calls=AUTO)\n","    dset = dset.map(augmix_fn, num_parallel_calls=AUTO) if do_augmix else dset # augmix\n","    dset = dset.cache(cache_dir) if cache else dset\n","    dset = dset.map(augment_fn, num_parallel_calls=AUTO) if augment else dset # augmentation\n","\n","    dset = dset.repeat() if repeat else dset\n","    dset = dset.shuffle(shuffle) if shuffle else dset\n","    dset = dset.batch(bsize).prefetch(AUTO)\n","    dset = dset.map(transform_cutmix, num_parallel_calls=AUTO) if do_cutmix else dset # cutmix\n","    return dset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["COMPETITION_NAME = 'siim-image'\n","strategy = auto_select_accelerator()\n","BATCH_SIZE = strategy.num_replicas_in_sync * 8\n","#GCS_DS_PATH = KaggleDatasets().get_gcs_path(COMPETITION_NAME)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2021-08-01T02:22:58.798581Z","iopub.status.busy":"2021-08-01T02:22:58.798213Z","iopub.status.idle":"2021-08-01T02:22:58.890173Z","shell.execute_reply":"2021-08-01T02:22:58.889154Z","shell.execute_reply.started":"2021-08-01T02:22:58.798551Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>Negative for Pneumonia</th>\n","      <th>Typical Appearance</th>\n","      <th>Indeterminate Appearance</th>\n","      <th>Atypical Appearance</th>\n","      <th>fold</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>00086460a852_study</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>000c9c05fd14_study</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>00292f8c37bd_study</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>005057b3f880_study</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0051d9b12e72_study</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>6049</th>\n","      <td>ffcb4630f46f_study</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>6050</th>\n","      <td>ffe4d6e8fbb0_study</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>6051</th>\n","      <td>ffe94fcb14fa_study</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>6052</th>\n","      <td>ffebf1ef4a9c_study</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>6053</th>\n","      <td>fff649d65f62_study</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>6054 rows × 6 columns</p>\n","</div>"],"text/plain":["                      id  Negative for Pneumonia  Typical Appearance  \\\n","0     00086460a852_study                       0                   1   \n","1     000c9c05fd14_study                       0                   0   \n","2     00292f8c37bd_study                       1                   0   \n","3     005057b3f880_study                       1                   0   \n","4     0051d9b12e72_study                       0                   0   \n","...                  ...                     ...                 ...   \n","6049  ffcb4630f46f_study                       0                   1   \n","6050  ffe4d6e8fbb0_study                       0                   1   \n","6051  ffe94fcb14fa_study                       0                   1   \n","6052  ffebf1ef4a9c_study                       0                   1   \n","6053  fff649d65f62_study                       0                   1   \n","\n","      Indeterminate Appearance  Atypical Appearance  fold  \n","0                            0                    0     3  \n","1                            0                    1     4  \n","2                            0                    0     0  \n","3                            0                    0     1  \n","4                            0                    1     2  \n","...                        ...                  ...   ...  \n","6049                         0                    0     2  \n","6050                         0                    0     3  \n","6051                         0                    0     4  \n","6052                         0                    0     4  \n","6053                         0                    0     0  \n","\n","[6054 rows x 6 columns]"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["# load df : train_study_level\n","load_dir = f\"/kaggle/input/{COMPETITION_NAME}/\"\n","df = pd.read_csv('/kaggle/input/siim-covid19-detection/train_study_level.csv') # for study_level\n","label_cols = df.columns[1:5]\n","gkf = GroupKFold(n_splits=5)\n","df['fold'] = -1\n","for fold, (train_index, valid_index) in enumerate(gkf.split(df, groups = df.id.tolist())):\n","    df.loc[valid_index,'fold'] = fold\n","df"]},{"cell_type":"markdown","metadata":{},"source":["# EfficientNetB7 Model Training"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2021-08-01T02:13:51.375257Z","iopub.status.idle":"2021-08-01T02:13:51.375878Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["if v1:\n","    for i in range(5): # K_FOLDS\n","        valid_paths = GCS_DS_PATH + '/study/' + df[df['fold']==i]['id'] + '.png' \n","        train_paths = GCS_DS_PATH + '/study/' + df[df['fold']!=i]['id'] + '.png' \n","        valid_labels = df[df['fold']==i][label_cols].values\n","        train_labels = df[df['fold']!=i][label_cols].values\n","\n","        IMSIZE = (224, 240, 260, 300, 380, 456, 528, 600) # study = 600\n","        IMS = 7\n","        \n","        # decoder\n","        decoder = build_decoder(with_labels=True,\n","                                target_size = (IMSIZE[IMS], IMSIZE[IMS]), \n","                                ext='png')\n","        test_decoder = build_decoder(with_labels=False, \n","                                     target_size = (IMSIZE[IMS], IMSIZE[IMS]), \n","                                     ext='png')\n","        \n","        # dataset\n","        train_dataset = build_dataset(\n","                train_paths, \n","                train_labels, \n","                bsize=BATCH_SIZE, \n","                decode_fn = decoder\n","        )\n","        \n","        valid_dataset = build_dataset(\n","                valid_paths, \n","                valid_labels, \n","                bsize=BATCH_SIZE, \n","                decode_fn = decoder,\n","                repeat=False, \n","                shuffle=False, \n","                augment=False\n","        )\n","\n","        try:\n","            n_labels = train_labels.shape[1]\n","        except:\n","            n_labels = 1\n","\n","        with strategy.scope():\n","            model = tf.keras.Sequential([\n","                efn.EfficientNetB7(\n","                    input_shape = (IMSIZE[IMS], IMSIZE[IMS], 3),\n","                    weights='imagenet',\n","                    include_top=False),\n","                tf.keras.layers.GlobalAveragePooling2D(),\n","                tf.keras.layers.Dense(n_labels, activation='softmax')\n","            ])\n","            model.compile(\n","                optimizer = tf.keras.optimizers.Adam(),\n","                loss='categorical_crossentropy',\n","                metrics=[tf.keras.metrics.AUC(multi_label=True)])\n","            model.summary()\n","\n","        steps_per_epoch = train_paths.shape[0] // BATCH_SIZE\n","        checkpoint = tf.keras.callbacks.ModelCheckpoint(\n","            f\"model{i}.h5\", save_best_only=True, monitor='val_loss', mode='min'\n","        )\n","        lr_reducer = tf.keras.callbacks.ReduceLROnPlateau(\n","            monitor='val_loss', patience=3, min_lr=1e-6, mode='min')\n","\n","        history = model.fit(\n","            train_dataset,\n","            epochs=20, # default 20\n","            verbose=1,\n","            callbacks = [checkpoint, lr_reducer],\n","            steps_per_epoch = steps_per_epoch,\n","            validation_data = valid_dataset\n","        )\n","        hist_df = pd.DataFrame(history.history)\n","        hist_df.to_csv(f\"history{i}.csv\")"]},{"cell_type":"markdown","metadata":{},"source":["# EfficientNetV2_XL model Training"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2021-08-01T02:23:04.057923Z","iopub.status.busy":"2021-08-01T02:23:04.057553Z","iopub.status.idle":"2021-08-01T02:23:04.498443Z","shell.execute_reply":"2021-08-01T02:23:04.497417Z","shell.execute_reply.started":"2021-08-01T02:23:04.057894Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["gs://kds-40f526733933c01f1885087fe24fcb06ce3f5c601cd74b3d084cfe68/tfhub_models/efficientnetv2-l-21k-ft1k/feature_vector\n"]}],"source":["# We first find the GCS path of the selected EffNetV2 architecture from the EffNetV2 weights Kaggle dataset\n","\n","if v2:\n","    # Get the Tensorflow Hub model URL\n","    hub_type = 'feature_vector' # ['classification', 'feature_vector']\n","    model_arch = \"efficientnetv2-l-21k-ft1k\"\n","    # Get the GCS path of EfficientNet Models\n","    DS_GCS_PATH = KaggleDatasets().get_gcs_path('efficientnetv2-tfhub-weight-files')\n","    MODEL_GCS_PATH = f\"{DS_GCS_PATH}/tfhub_models/{model_arch}/{hub_type}\"\n","    print(MODEL_GCS_PATH)"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2021-08-01T02:23:04.500093Z","iopub.status.busy":"2021-08-01T02:23:04.499816Z","iopub.status.idle":"2021-08-01T02:23:04.505065Z","shell.execute_reply":"2021-08-01T02:23:04.504121Z","shell.execute_reply.started":"2021-08-01T02:23:04.500067Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["model path\n"]}],"source":["if v2:\n","    trained_model_path = '/kaggle/working/effnetV2_model'\n","    if not os.path.isdir(trained_model_path):\n","        os.makedirs(trained_model_path)\n","    else:\n","        shutil.rmtree(trained_model_path)\n","    print('model path')"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2021-08-01T02:23:29.018675Z","iopub.status.busy":"2021-08-01T02:23:29.018215Z","iopub.status.idle":"2021-08-01T02:23:29.033201Z","shell.execute_reply":"2021-08-01T02:23:29.032210Z","shell.execute_reply.started":"2021-08-01T02:23:29.018642Z"},"trusted":true},"outputs":[{"data":{"text/plain":["<tensorflow.python.keras.engine.input_layer.InputLayer at 0x7f801dffa510>"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["tf.keras.layers.InputLayer(input_shape = [768,768,3])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["view_model = True\n","if view_model:\n","    model = tf.keras.Sequential([\n","                    # Explicitly define the input shape so the model can be properly\n","                    # loaded by the TFLite Converter (input layer 를 명시적으로 설정)\n","                    tf.keras.layers.InputLayer(input_shape = [IMSIZE[IMS],IMSIZE[IMS],3]),\n","                    tfhub.KerasLayer(MODEL_GCS_PATH, trainable=True),\n","                    tf.keras.layers.Dropout(rate=0.1),\n","                    tf.keras.layers.Dense(n_labels, activation='softmax')\n","                ])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-07-31T02:44:47.758671Z","iopub.status.busy":"2021-07-31T02:44:47.758124Z","iopub.status.idle":"2021-07-31T02:44:48.581451Z","shell.execute_reply":"2021-07-31T02:44:48.579121Z","shell.execute_reply.started":"2021-07-31T02:44:47.758636Z"},"trusted":true},"outputs":[],"source":["if v2:\n","    print(f\"Dataset Name : {COMPETITION_NAME}\")\n","    strategy = auto_select_accelerator() #Define TPU strategy and clear TPU - try to select TPU else GPU or CPU\n","    GCS_DS_PATH = KaggleDatasets().get_gcs_path(COMPETITION_NAME)\n","    BATCH_SIZE = strategy.num_replicas_in_sync * 8\n","    for i in range(5):\n","        print(f\"Fold {i} start\")        \n","        # Converting global config class object to a dictionary to log using Wandb\n","        # --- remove ---\n","        detail_path = '/new_resized_data/study_768/'\n","        valid_paths = GCS_DS_PATH + detail_path + df[df['fold'] == i]['id'] + '.png'\n","        train_paths = GCS_DS_PATH + detail_path + df[df['fold'] != i]['id'] + '.png'\n","        valid_labels = df[df['fold'] == i][label_cols].values\n","        train_labels = df[df['fold'] != i][label_cols].values\n","        \n","        IMSIZE = (768,)\n","        IMS = 0\n","        # image_level file 을 사용하므로 img_size = 512\n","        \n","        # train image decoder\n","        decoder = build_decoder(with_labels=True,\n","                                target_size=(IMSIZE[IMS], IMSIZE[IMS]),\n","                                ext='png')\n","        # valid build decoder\n","        test_decoder = build_decoder(with_labels=False,\n","                                     target_size=(IMSIZE[IMS], IMSIZE[IMS]),\n","                                     ext='png')\n","        \n","        train_dataset = build_dataset(train_paths,\n","                                      train_labels,\n","                                      bsize=BATCH_SIZE,\n","                                      decode_fn=decoder,\n","                                      augment=True,\n","                                      do_cutmix=False,\n","                                      do_augmix=False)\n","        \n","        valid_dataset = build_dataset(valid_paths,\n","                                      valid_labels,\n","                                      bsize=BATCH_SIZE,\n","                                      decode_fn=decoder,\n","                                      repeat=False,\n","                                      shuffle=False,\n","                                      augment=False,\n","                                      do_cutmix=False,\n","                                      do_augmix=False)\n","        try:\n","            n_labels = train_labels.shape[1]\n","        except:\n","            n_labels = 1\n","        # n_labels 부분은 num_classes -> for Dense output size\n","        print(n_labels)\n","        with strategy.scope():\n","            model = tf.keras.Sequential([\n","                # Explicitly define the input shape so the model can be properly\n","                # loaded by the TFLite Converter (input layer 를 명시적으로 설정)\n","                tf.keras.layers.InputLayer(input_shape = [IMSIZE[IMS],IMSIZE[IMS],3]),\n","                tfhub.KerasLayer(MODEL_GCS_PATH, trainable=True),\n","                tf.keras.layers.Dropout(rate=0.1),\n","                tf.keras.layers.Dense(n_labels, activation='softmax')\n","            ])\n","            model.compile(optimizer = tf.keras.optimizers.Adam(),\n","                          loss='categorical_crossentropy',\n","                          metrics = [tf.keras.metrics.AUC(multi_label=False)])\n","            model.summary()\n","            \n","        steps_per_epoch = train_paths.shape[0] // BATCH_SIZE \n","        checkpoint = tf.keras.callbacks.ModelCheckpoint(f'{trained_model_path}/model{i}_2class.h5', \n","                                                        save_best_only=True, \n","                                                        monitor='val_loss',\n","                                                        mode='min')\n","\n","        lr_reducer = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n","                                                          patience=3,\n","                                                          min_lr=1e-6,\n","                                                          mode='min')\n","        annealing = tf.keras.experimental.CosineDecayRestarts(initial_learning_rate=0.0001,\n","                                                              first_decay_steps=10,\n","                                                              t_mul=1.0,\n","                                                              m_mul=1.0,\n","                                                              alpha=0.0)\n","        lr_callback = tf.keras.callbacks.LearningRateScheduler(annealing, verbose = True)\n","        \n","        history = model.fit(train_dataset,\n","                            epochs=20,\n","                            verbose=1,\n","                            callbacks=[checkpoint, lr_reducer],\n","                            steps_per_epoch=steps_per_epoch,\n","                            validation_data=valid_dataset)\n","\n","        hist_df = pd.DataFrame(history.history)\n","        hist_df.to_csv(f\"{trained_model_path}/history{i}_2class.csv\")\n","        \n","# efficientnetV2_XL paramter\n","# Total params: 117,748,129\n","# Trainable params: 117,235,553\n","# Non-trainable params: 512,576"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-06-29T11:35:58.072105Z","iopub.status.busy":"2021-06-29T11:35:58.071676Z","iopub.status.idle":"2021-06-29T11:39:53.041979Z","shell.execute_reply":"2021-06-29T11:39:53.040641Z","shell.execute_reply.started":"2021-06-29T11:35:58.072071Z"},"trusted":true},"outputs":[],"source":["#zip model\n","#!zip -r study_model.zip ./*"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-06-29T11:45:18.716111Z","iopub.status.busy":"2021-06-29T11:45:18.715673Z","iopub.status.idle":"2021-06-29T11:45:18.754972Z","shell.execute_reply":"2021-06-29T11:45:18.754068Z","shell.execute_reply.started":"2021-06-29T11:45:18.716073Z"},"trusted":true},"outputs":[],"source":["efnb7_history = [f\"../input/siimcovid19efnb7trainstudy/history{i}.csv\" for i in range(5)]\n","cols = pd.read_csv(efnb7_history[0]).columns\n","cols"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-06-29T11:50:03.854193Z","iopub.status.busy":"2021-06-29T11:50:03.853771Z","iopub.status.idle":"2021-06-29T11:50:05.284204Z","shell.execute_reply":"2021-06-29T11:50:05.283375Z","shell.execute_reply.started":"2021-06-29T11:50:03.854161Z"},"trusted":true},"outputs":[],"source":["fig, axes = plt.subplots(3,2, figsize=(18,18))\n","\n","for i in range(6): # cols\n","    for j in range(5): # folds\n","        temp = pd.read_csv(efnb7_history[j])\n","        axes[i//2][i%2].plot(temp[temp.columns[i]], label = f\"fold {j} {temp.columns[i]}\")\n","        axes[i//2][i%2].legend(loc='best')\n","        axes[i//2][i%2].set_title(f\"{cols[i]}\", size=20)\n","plt.show();"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"interpreter":{"hash":"0ba4c1c78cb01f81f23e4b3fe93b7c67e3b3309ccfffba34bf749370e6b9d870"},"kernelspec":{"display_name":"Python 3.8.10 64-bit","name":"python3"},"language_info":{"name":"python","version":""}},"nbformat":4,"nbformat_minor":4}